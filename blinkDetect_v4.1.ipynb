{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import peakutils\n",
    "\n",
    "from peakutils.plot import plot as pplot\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import savefig\n",
    "\n",
    "import re\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'BaGELS'\n",
    "\n",
    "dataFolder = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSubjectNumber(filename):\n",
    "    subjNumberRegex = re.compile('''\n",
    "    # filename will be something like 'OpenBCI-RAW-28211_SBR_Pre1.txt'\n",
    "    # Regex looks for a 1-to-6 digit string in the filename, as used by CCDL.\n",
    "    ([0-9]{1,6})\n",
    "    ''', re.VERBOSE)\n",
    "\n",
    "    extractSubjNumber = subjNumberRegex.findall(filename)\n",
    "    subjNumber = extractSubjNumber[0]\n",
    "\n",
    "    return subjNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tsClean(df, seconds=30):\n",
    "    '''\n",
    "    Function to clean data by (1) making timeseries stationary, (2) removing low & high frequency signal components,\n",
    "    (3) smoothing, and (4) discarding the first and last X seconds of the time series. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas DataFrame containing OpenBCI Gangion or Cyton data where column 0 is the sample number, column 1\n",
    "         is an ndarray for Channel One, and column 2 is an ndarray for Channel Two. Other column data is discarded.\n",
    "         \n",
    "    seconds : Length of time series data to discard at the beginning and end of recording. 30 seconds by default.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame with stationary, denoised, and smoothed, truncated data for Channels One and Two only.\n",
    "    '''\n",
    "    \n",
    "    samplingRate = np.max(df[0]) # extracting sampling rate from max sample index value   \n",
    "    lowerBoundary = samplingRate*seconds # lower cutoff for sEBR recording\n",
    "    upperBoundary = len(df[1])-(lowerBoundary) # upper cutoff for sEBR recording\n",
    "\n",
    "\n",
    "    # (1) Differencing\n",
    "    period = 1\n",
    "    c1_shift = df[1] - df[1].shift(periods = period)\n",
    "    c2_shift = df[2] - df[2].shift(periods = period)\n",
    "    \n",
    "    # (2) FFT Denoising\n",
    "    c1_shift_fft = np.fft.fft(c1_shift[period:]) # [period:] ensures NaN created by pd.shift() is dropped\n",
    "    c1_shift_fft[0:1] = 0\n",
    "    c1_shift_fft[2500:] = 0 # ToDo: Refine high frequency cutoff\n",
    "    c1_shift_ifft = np.fft.ifft(c1_shift_fft)\n",
    "    \n",
    "    c2_shift_fft = np.fft.fft(c2_shift[period:])\n",
    "    c2_shift_fft[0:1] = 0\n",
    "    c2_shift_fft[2500:] = 0\n",
    "    c2_shift_ifft = np.fft.ifft(c2_shift_fft)\n",
    "    \n",
    "    # (3) Smoothing\n",
    "    c1_shift_ifft = pd.DataFrame(c1_shift_ifft)\n",
    "    c1_shift_ifft_smoothed = c1_shift_ifft.rolling(window=25).mean()\n",
    "    \n",
    "    c2_shift_ifft = pd.DataFrame(c2_shift_ifft)\n",
    "    c2_shift_ifft_smoothed = c2_shift_ifft.rolling(window=25).mean()\n",
    "    \n",
    "    \n",
    "    # (4) Truncating\n",
    "    c1_relevant = c1_shift_ifft_smoothed[lowerBoundary:upperBoundary]\n",
    "    c2_relevant = c2_shift_ifft_smoothed[lowerBoundary:upperBoundary]\n",
    "    \n",
    "    c1c2 = c1_relevant\n",
    "    c1c2[1] = c2_relevant[0]\n",
    "    \n",
    "    return c1c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Counting blinks for all .txt files in data directory. \n",
    "# Creates .csv with subject number and blinks for each channel, saved in root directory. \n",
    "subjectNumberList = []\n",
    "channelOneBlinkList = []\n",
    "channelTwoBlinkList = []\n",
    "for folderName, subfolders, filenames in os.walk(dataFolder):\n",
    "\n",
    "    for file in filenames:\n",
    "        if file.endswith('.txt'):\n",
    "            raw = pd.read_table(dataFolder + file, sep = ',', skiprows=6, header=None)\n",
    "\n",
    "            subjectNo = getSubjectNumber(file)\n",
    "            subjectNumberList.append(subjectNo)\n",
    "            \n",
    "            processed = tsClean(raw)\n",
    "            \n",
    "            c1_peakIndexes = peakutils.indexes(pd.Series.as_matrix(processed[0]), min_dist=15, thres=0.60)\n",
    "            c2_peakIndexes = peakutils.indexes(pd.Series.as_matrix(processed[1]), min_dist=15, thres=0.60)\n",
    "            \n",
    "            c1_blinks = len(c1_peakIndexes)\n",
    "            c2_blinks = len(c2_peakIndexes)\n",
    "            channelOneBlinkList.append(c1_blinks)\n",
    "            channelTwoBlinkList.append(c2_blinks)\n",
    "            \n",
    "            \n",
    "            # Plotting timeseries\n",
    "        \n",
    "            if not os.path.exists('./tsPlots'):\n",
    "                os.makedirs('./tsPlots')\n",
    "            \n",
    "            x = np.arange(len(pd.Series.as_matrix(processed[0])))\n",
    "            y = pd.Series.as_matrix((processed[0]))\n",
    "            plt.figure(figsize=(100,15), dpi = 300)\n",
    "            pplot(x, y, c1_peakIndexes)\n",
    "            savefig('./tsPlots/' + subjectNo + '_channelOne.png')\n",
    "            plt.close()\n",
    "\n",
    "            x = np.arange(len(pd.Series.as_matrix(processed[1])))\n",
    "            y = pd.Series.as_matrix((processed[1] ))           \n",
    "            plt.figure(figsize=(100,15), dpi = 300)\n",
    "            pplot(x, y, c2_peakIndexes)\n",
    "            savefig('./tsPlots/' + subjectNo + '_channelTwo.png')\n",
    "            plt.close() \n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "currentDateTime = time.strftime(\"%m.%d.%Y_%H.%M%p\")\n",
    "filename = project + '_blinkDetect_v4.1_output_' + currentDateTime + '.csv'\n",
    "blinkOutput = open(filename, 'w')\n",
    "\n",
    "blinkOutput.write('SubjectNo' + ',' + 'channelOneBlinks' + ',' + 'channelTwoBlinks' + '\\n')\n",
    "zipped = zip(subjectNumberList, channelOneBlinkList, channelTwoBlinkList)\n",
    "for i, j, k in zipped:\n",
    "    blinkOutput.write(str(i) + ',' + str(j) + ',' + str(k) + '\\n')\n",
    "blinkOutput.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('sEBR count finished. Please check root folder for output.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Py3.5]",
   "language": "python",
   "name": "conda-env-Py3.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
